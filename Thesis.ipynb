{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhQPtyOeTYjXhG8Bc6CZiR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zbatzioutilburg/Thesis/blob/main/Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZDWSOMYsZdZ"
      },
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw56CNnDr7NQ"
      },
      "source": [
        "pip install PyPortfolioOpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7BVCGdFcqNe"
      },
      "source": [
        "### Import libraries.\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import IPython\n",
        "import IPython.display\n",
        "import keras_tuner as kt\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from functools import reduce\n",
        "import pypfopt\n",
        "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADLW7u3Lc4zd"
      },
      "source": [
        "random.seed(1)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYkDU-tPdtbc"
      },
      "source": [
        "### Import data csv files, set index as datetime\n",
        "### and calculate logarithmic returns.\n",
        "\n",
        "#Macroeconomic variables\n",
        "\n",
        "CPIAUCSL = pd.read_csv('CPIAUCSL.csv', sep = ',', index_col = 0)\n",
        "CPIAUCSL.index = pd.to_datetime(CPIAUCSL.index)\n",
        "CPIAUCSL = np.log(CPIAUCSL.CPIAUCSL) - np.log(CPIAUCSL.CPIAUCSL.shift(1))\n",
        "\n",
        "CSUSHPISA = pd.read_csv('CSUSHPISA.csv', sep = ',', index_col = 0)\n",
        "CSUSHPISA.index = pd.to_datetime(CSUSHPISA.index)\n",
        "CSUSHPISA = np.log(CSUSHPISA.CSUSHPISA) - np.log(CSUSHPISA.CSUSHPISA.shift(1))\n",
        "\n",
        "IQ = pd.read_csv('IQ.csv', sep = ',', index_col = 0)\n",
        "IQ.index = pd.to_datetime(IQ.index)\n",
        "IQ = np.log(IQ.IQ) - np.log(IQ.IQ.shift(1))\n",
        "\n",
        "IR = pd.read_csv('IR.csv', sep = ',', index_col = 0)\n",
        "IR.index = pd.to_datetime(IR.index)\n",
        "IR = np.log(IR.IR) - np.log(IR.IR.shift(1))\n",
        "\n",
        "MCOILWTICO = pd.read_csv('MCOILWTICO.csv', sep = ',', index_col = 0)\n",
        "MCOILWTICO.index = pd.to_datetime(MCOILWTICO.index)\n",
        "MCOILWTICO = np.log(MCOILWTICO.MCOILWTICO) - np.log(MCOILWTICO.MCOILWTICO.shift(1))\n",
        "\n",
        "MICH = pd.read_csv('MICH.csv', sep = ',', index_col = 0)\n",
        "MICH.index = pd.to_datetime(MICH.index)\n",
        "MICH = np.log(MICH.MICH) - np.log(MICH.MICH.shift(1))\n",
        "\n",
        "PPIACO = pd.read_csv('PPIACO.csv', sep = ',', index_col = 0)\n",
        "PPIACO.index = pd.to_datetime(PPIACO.index)\n",
        "PPIACO = np.log(PPIACO.PPIACO) - np.log(PPIACO.PPIACO.shift(1))\n",
        "\n",
        "PSAVERT = pd.read_csv('PSAVERT.csv', sep = ',', index_col = 0)\n",
        "PSAVERT.index = pd.to_datetime(PSAVERT.index)\n",
        "PSAVERT = np.log(PSAVERT.PSAVERT) - np.log(PSAVERT.PSAVERT.shift(1))\n",
        "\n",
        "TB3MS = pd.read_csv('TB3MS.csv', sep = ',', index_col = 0)\n",
        "TB3MS.index = pd.to_datetime(TB3MS.index)\n",
        "TB3MS = np.log(TB3MS.TB3MS) - np.log(TB3MS.TB3MS.shift(1))\n",
        "\n",
        "TWEXBMTH = pd.read_csv('TWEXBMTH.csv', sep = ',', index_col = 0)\n",
        "TWEXBMTH.index = pd.to_datetime(TWEXBMTH.index)\n",
        "TWEXBMTH = np.log(TWEXBMTH.TWEXBMTH) - np.log(TWEXBMTH.TWEXBMTH.shift(1))\n",
        "\n",
        "USD1MTD156N = pd.read_csv('USD1MTD156N.csv', sep = ',', index_col = 0)\n",
        "USD1MTD156N.index = pd.to_datetime(USD1MTD156N.index)\n",
        "\n",
        "\n",
        "#Financial variables\n",
        "NAESX = pd.read_csv('NAESX.csv', sep = ',', index_col = 0)\n",
        "NAESX.index = pd.to_datetime(NAESX.index)\n",
        "NAESX = NAESX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "NAESX.columns = ['NAESX Adj. Close']\n",
        "NAESX = np.log(NAESX['NAESX Adj. Close']) - np.log(NAESX['NAESX Adj. Close'].shift(1))\n",
        "\n",
        "VBMFX = pd.read_csv('VBMFX.csv', sep = ',', index_col = 0)\n",
        "VBMFX.index = pd.to_datetime(VBMFX.index)\n",
        "VBMFX = VBMFX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VBMFX.columns = ['VBMFX Adj. Close']\n",
        "VBMFX = np.log(VBMFX['VBMFX Adj. Close']) - np.log(VBMFX['VBMFX Adj. Close'].shift(1))\n",
        "\n",
        "VEIEX = pd.read_csv('VEIEX.csv', sep = ',', index_col = 0)\n",
        "VEIEX.index = pd.to_datetime(VEIEX.index)\n",
        "VEIEX = VEIEX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VEIEX.columns = ['VEIEX Adj. Close']\n",
        "VEIEX = np.log(VEIEX['VEIEX Adj. Close']) - np.log(VEIEX['VEIEX Adj. Close'].shift(1))\n",
        "\n",
        "VFINX = pd.read_csv('VFINX.csv', sep = ',', index_col = 0)\n",
        "VFINX.index = pd.to_datetime(VFINX.index)\n",
        "VFINX = VFINX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VFINX.columns = ['VFINX Adj. Close']\n",
        "VFINX = np.log(VFINX['VFINX Adj. Close']) - np.log(VFINX['VFINX Adj. Close'].shift(1))\n",
        "\n",
        "VGSLX = pd.read_csv('VGSLX.csv', sep = ',', index_col = 0)\n",
        "VGSLX.index = pd.to_datetime(VGSLX.index)\n",
        "VGSLX = VGSLX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VGSLX.columns = ['VGSLX Adj. Close']\n",
        "VGSLX = np.log(VGSLX['VGSLX Adj. Close']) - np.log(VGSLX['VGSLX Adj. Close'].shift(1))\n",
        "\n",
        "VGTSX = pd.read_csv('VGTSX.csv', sep = ',', index_col = 0)\n",
        "VGTSX.index = pd.to_datetime(VGTSX.index)\n",
        "VGTSX = VGTSX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VGTSX.columns = ['VGTSX Adj. Close']\n",
        "VGTSX = np.log(VGTSX['VGTSX Adj. Close']) - np.log(VGTSX['VGTSX Adj. Close'].shift(1))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW9tyU3GeeaM"
      },
      "source": [
        "### The Libor dataset has daily values.\n",
        "### They will be converted to monthly values, averaging per month.\n",
        "### The Libor dataset index is converted to datetime.\n",
        "\n",
        "USD1MTD156N.USD1MTD156N = USD1MTD156N.USD1MTD156N.replace('.', '')\n",
        "USD1MTD156N.index = pd.to_datetime(USD1MTD156N.index)\n",
        "USD1MTD156N.USD1MTD156N = pd.to_numeric(USD1MTD156N.USD1MTD156N)\n",
        "USD1MTD156N = USD1MTD156N.resample('1MS').mean()\n",
        "USD1MTD156N = np.log(USD1MTD156N.USD1MTD156N) - np.log(USD1MTD156N.USD1MTD156N.shift(1))"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMG_8q_nem1X"
      },
      "source": [
        "### Prepare the datasets.\n",
        "input_variables = [CPIAUCSL, CSUSHPISA, IQ, IR,\n",
        "                   MCOILWTICO, MICH, PPIACO, PSAVERT,\n",
        "                   TB3MS, TWEXBMTH, USD1MTD156N]\n",
        "\n",
        "output_variables = [NAESX, VBMFX, VEIEX, VFINX, VGSLX, VGTSX]\n",
        "\n",
        "X = reduce(lambda left, right : pd.merge(left, right,\n",
        "                                         left_index = True, right_index = True,\n",
        "                                         how = 'outer'), input_variables)\n",
        "\n",
        "y = reduce(lambda left, right : pd.merge(left, right,\n",
        "                                         left_index = True, right_index = True,\n",
        "                                         how = 'outer'), output_variables)\n",
        "\n",
        "X = X['2002-01-01' : '2019-12-01']\n",
        "y = y['2002-01-01' : '2019-12-01']\n",
        "y = y.fillna(0.0)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HirFjoelIRo"
      },
      "source": [
        "### Split the data into train, validation and test sets,\n",
        "### with analogy of 70%, 15% and 15%, respectively.\n",
        "X_train = X[0 : int(0.7*len(X))]\n",
        "X_val = X[int(0.7*len(X)) : int(0.85*len(X))]\n",
        "X_test = X[int(0.85*len(X)) : ]\n",
        "y_train = y[0: int(0.7*len(y))]\n",
        "y_val = y[int(0.7*len(y)) : int(0.85*len(y))]\n",
        "y_test = y[int(0.85*len(y)) : ]"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp5KdvlgoSjh"
      },
      "source": [
        "### Convert to numpy arrays.\n",
        "X_train = X_train.values\n",
        "X_val = X_val.values\n",
        "X_test = X_test.values\n",
        "y_train = y_train.values\n",
        "y_val = y_val.values\n",
        "y_test = y_test.values"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38c6SK7QmosC"
      },
      "source": [
        "### Data standardization.\n",
        "X_train = (X_train - X_train.mean()) / X_train.std()\n",
        "X_val = (X_val - X_train.mean()) / X_train.std()\n",
        "X_test = (X_test - X_train.mean()) / X_train.std()"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf2cFhXgu8sO"
      },
      "source": [
        "Multi-Layer Perceptron (MLP Baseline Model - 1 hidden hayer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7PSA9jiu-S5"
      },
      "source": [
        "### Create MLP model with the use of a function.\n",
        "def mlp_builder(hp):\n",
        "  hp_units = hp.Int('units', min_value = 10, max_value = 100, step = 10)\n",
        "  hp_learning_rate = hp.Choice('learning_rate',\n",
        "                               values = [1e-1, 1e-2, 1e-3, 1e-4])\n",
        "  hp_activation = hp.Choice('activation',\n",
        "                            values = ['relu', 'tanh', 'sigmoid'])\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add((keras.layers.Dense(units = hp_units,\n",
        "                                     activation = hp_activation,\n",
        "                                     input_dim = X_train.shape[1])))\n",
        "  model.add(keras.layers.Dense(y_train.shape[1]))\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate = hp_learning_rate),\n",
        "                loss = 'mse',\n",
        "                metrics = tf.keras.metrics.RootMeanSquaredError())\n",
        "  return model"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBVziKyCvVPH"
      },
      "source": [
        "### Instantiate the tuner and perform hyperparameter tuning.\n",
        "tuner = kt.Hyperband(mlp_builder,\n",
        "                     objective = 'val_loss',\n",
        "                     max_epochs = 10,\n",
        "                     directory = 'keras_tuner_dir',\n",
        "                     project_name = 'keras_mlp',\n",
        "                     overwrite = True)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr6SHjDEv-Lz"
      },
      "source": [
        "### Early Stopping definition.\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgBiL9KxwBnc",
        "outputId": "ccc3df2e-63c5-491a-cadf-f055e261bdfd"
      },
      "source": [
        "### Hyperparameters search for 5 epochs.\n",
        "tuner.search(X_train, y_train,\n",
        "             epochs = 5, validation_data = (X_val, y_val),\n",
        "             callbacks = [stop_early])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 02s]\n",
            "val_loss: 0.11313724517822266\n",
            "\n",
            "Best val_loss So Far: 0.0018050395883619785\n",
            "Total elapsed time: 00h 00m 38s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti0wPPBhwIA_"
      },
      "source": [
        "# Get the optimal hyperparameters.\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz4fWalOwKOs",
        "outputId": "961a23ff-ac24-4584-bab1-df392746f2bf"
      },
      "source": [
        "print(f\"\"\"\n",
        "The hyperparameter search for MLP is complete.\n",
        "The optimal number of units in the first hidden\n",
        "layer is {best_hps.get('units')},\n",
        "the optimal activation function is {best_hps.get('activation')}\n",
        "and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The hyperparameter search for MLP is complete.\n",
            "The optimal number of units in the first hidden\n",
            "layer is 80,\n",
            "the optimal activation function is sigmoid\n",
            "and the optimal learning rate for the optimizer\n",
            "is 0.01.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7j6ZVoxwVg3",
        "outputId": "860b3c27-3a9b-4d71-d0ac-130f8fbf3ff8"
      },
      "source": [
        "### Find the optimal number of epochs to train the model with the hyperparameters\n",
        "### obtained from the search. Build the model with the optimal hyperparameters\n",
        "### and train it on the data for 200 epochs.\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=200, validation_data = (X_val, y_val))\n",
        "\n",
        "val_rmse_per_epoch = history.history['val_root_mean_squared_error']\n",
        "\n",
        "best_epoch = val_rmse_per_epoch.index(min(val_rmse_per_epoch))\n",
        "\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 37ms/step - loss: 0.2111 - root_mean_squared_error: 0.4594 - val_loss: 0.1247 - val_root_mean_squared_error: 0.3532\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1118 - root_mean_squared_error: 0.3344 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1609\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0457 - val_root_mean_squared_error: 0.2137\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0347 - root_mean_squared_error: 0.1864 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0148 - root_mean_squared_error: 0.1216 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0150 - root_mean_squared_error: 0.1226 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0081 - root_mean_squared_error: 0.0897 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0896\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0545\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0037 - root_mean_squared_error: 0.0612 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0545\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0497\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0027 - root_mean_squared_error: 0.0519 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0428\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0028 - root_mean_squared_error: 0.0533 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0401\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0026 - root_mean_squared_error: 0.0511 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0425\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - root_mean_squared_error: 0.0496 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0389\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0024 - root_mean_squared_error: 0.0492 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0391\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0024 - root_mean_squared_error: 0.0485 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0392\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - root_mean_squared_error: 0.0483 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0383\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - root_mean_squared_error: 0.0476 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0023 - root_mean_squared_error: 0.0479 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0393\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0024 - root_mean_squared_error: 0.0487 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0414\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - root_mean_squared_error: 0.0488 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0388\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0493 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0413\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0472 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0383\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0022 - root_mean_squared_error: 0.0473 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0400\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0467 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - root_mean_squared_error: 0.0462 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0461 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0364\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0459 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0464 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0396\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0023 - root_mean_squared_error: 0.0475 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0389\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - root_mean_squared_error: 0.0479 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0405\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0492 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0474 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0385\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0023 - root_mean_squared_error: 0.0478 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0394\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0468 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0407\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - root_mean_squared_error: 0.0486 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0023 - root_mean_squared_error: 0.0483 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0417\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0024 - root_mean_squared_error: 0.0491 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0427\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - root_mean_squared_error: 0.0496 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0391\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - root_mean_squared_error: 0.0473 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0456\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - root_mean_squared_error: 0.0482 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0386\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0388\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0456 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0458 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0399\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0402\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0458 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - root_mean_squared_error: 0.0461 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0392\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0450 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0020 - root_mean_squared_error: 0.0451 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0452\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0024 - root_mean_squared_error: 0.0494 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0406\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - root_mean_squared_error: 0.0462 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0415\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0021 - root_mean_squared_error: 0.0461 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0408\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0461 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0454 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0402\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0454 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0402\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - root_mean_squared_error: 0.0480 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0422\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - root_mean_squared_error: 0.0497 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0445\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0473 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0409\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0458 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0398\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0456 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0411\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0023 - root_mean_squared_error: 0.0483 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0455\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - root_mean_squared_error: 0.0489 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0460 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0442\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0473 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0462 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0425\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - root_mean_squared_error: 0.0481 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0394\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0020 - root_mean_squared_error: 0.0450 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0430\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0463 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0490 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0408\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - root_mean_squared_error: 0.0484 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0367\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - root_mean_squared_error: 0.0482 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0487 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0419\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0452 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0386\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0394\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0019 - root_mean_squared_error: 0.0437 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - root_mean_squared_error: 0.0436 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0407\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0450 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0387\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0469 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0462\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0026 - root_mean_squared_error: 0.0509 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0448\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0026 - root_mean_squared_error: 0.0510 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0536\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0025 - root_mean_squared_error: 0.0502 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0446\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0023 - root_mean_squared_error: 0.0481 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0496\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0024 - root_mean_squared_error: 0.0486 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0454 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0408\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0393\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - root_mean_squared_error: 0.0436 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0445 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0467\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0460 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0401\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0464 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0438\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0023 - root_mean_squared_error: 0.0476 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0390\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - root_mean_squared_error: 0.0467 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0402\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - root_mean_squared_error: 0.0478 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0389\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - root_mean_squared_error: 0.0495 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0410\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0402\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0450 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0386\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0462 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0480\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0461 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0396\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0398\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - root_mean_squared_error: 0.0434 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0019 - root_mean_squared_error: 0.0437 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0400\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0460 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0546\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0474 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0404\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - root_mean_squared_error: 0.0453 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0454\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0472 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0444\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0389\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - root_mean_squared_error: 0.0433 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0415\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - root_mean_squared_error: 0.0435 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0395\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0020 - root_mean_squared_error: 0.0450 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0472 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0405\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0403\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0445 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0383\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0452 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0399\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - root_mean_squared_error: 0.0430 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0534\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0461 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0440\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0463 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0417\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - root_mean_squared_error: 0.0451 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0455\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0444 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0395\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - root_mean_squared_error: 0.0495 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0489\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0492 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0453 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0454\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0464 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0461\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0460 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0458 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0388\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - root_mean_squared_error: 0.0484 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0401\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0028 - root_mean_squared_error: 0.0525 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0484\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0029 - root_mean_squared_error: 0.0541 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0450\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0030 - root_mean_squared_error: 0.0547 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0406\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0028 - root_mean_squared_error: 0.0528 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0428\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0490 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0464\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0026 - root_mean_squared_error: 0.0510 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0438\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0433\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0490 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0460\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0025 - root_mean_squared_error: 0.0502 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0485\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0026 - root_mean_squared_error: 0.0506 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0437\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0449 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0391\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0445 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0407\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0421 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0417\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0017 - root_mean_squared_error: 0.0411 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0393\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - root_mean_squared_error: 0.0428 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0393\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0390\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0446 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0405\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0486 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0416\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0435\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0417\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0463 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0405\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0458\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0460 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0427\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0405\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0455 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0436\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0020 - root_mean_squared_error: 0.0451 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0422\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - root_mean_squared_error: 0.0429 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0422\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0424 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0478\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - root_mean_squared_error: 0.0444 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0425\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - root_mean_squared_error: 0.0461 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0391\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0445\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0463 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0444\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0451 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0455\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0017 - root_mean_squared_error: 0.0416 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0390\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0425 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - root_mean_squared_error: 0.0412 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0432\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0429 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0435\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0423 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0399\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - root_mean_squared_error: 0.0423 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0421\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0420 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0017 - root_mean_squared_error: 0.0409 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0404\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0430 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0468 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0451 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0417\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - root_mean_squared_error: 0.0449 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0424\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0455 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0458\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0446 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0467\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0020 - root_mean_squared_error: 0.0445 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0387\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - root_mean_squared_error: 0.0429 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0423\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - root_mean_squared_error: 0.0432 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0386\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - root_mean_squared_error: 0.0423 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0442\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - root_mean_squared_error: 0.0432 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0455\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0420 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - root_mean_squared_error: 0.0422 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0396\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0421 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0428\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - root_mean_squared_error: 0.0422 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0431\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - root_mean_squared_error: 0.0437 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0458\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0402\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - root_mean_squared_error: 0.0436 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0408\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0430\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - root_mean_squared_error: 0.0446 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0421\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - root_mean_squared_error: 0.0458 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0408\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - root_mean_squared_error: 0.0435 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0410\n",
            "Best epoch: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP52fmGNwnVo",
        "outputId": "127c1ac1-b67a-4d96-e30f-50cb974a92e1"
      },
      "source": [
        "### Pass the optimal hyperparameters to hypermodel.\n",
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "### Retrain the model with the optimal number of epochs.\n",
        "hypermodel.fit(X_train, y_train,\n",
        "               epochs=best_epoch,\n",
        "               validation_data = (X_val, y_val),\n",
        "               shuffle = False)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "5/5 [==============================] - 1s 39ms/step - loss: 0.3882 - root_mean_squared_error: 0.6230 - val_loss: 0.0859 - val_root_mean_squared_error: 0.2930\n",
            "Epoch 2/28\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1538 - root_mean_squared_error: 0.3922 - val_loss: 0.1370 - val_root_mean_squared_error: 0.3701\n",
            "Epoch 3/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0845 - root_mean_squared_error: 0.2907 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
            "Epoch 4/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0369 - root_mean_squared_error: 0.1920 - val_loss: 0.0550 - val_root_mean_squared_error: 0.2345\n",
            "Epoch 5/28\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0376 - root_mean_squared_error: 0.1939 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
            "Epoch 6/28\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0143 - root_mean_squared_error: 0.1195 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
            "Epoch 7/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0151 - root_mean_squared_error: 0.1230 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n",
            "Epoch 8/28\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0069 - root_mean_squared_error: 0.0829 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0689\n",
            "Epoch 9/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0070 - root_mean_squared_error: 0.0836 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
            "Epoch 10/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0044 - root_mean_squared_error: 0.0662 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0498\n",
            "Epoch 11/28\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0037 - root_mean_squared_error: 0.0612 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0492\n",
            "Epoch 12/28\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0031 - root_mean_squared_error: 0.0559 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0407\n",
            "Epoch 13/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0029 - root_mean_squared_error: 0.0538 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0426\n",
            "Epoch 14/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0025 - root_mean_squared_error: 0.0503 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 15/28\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - root_mean_squared_error: 0.0500 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 16/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0023 - root_mean_squared_error: 0.0478 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0381\n",
            "Epoch 17/28\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - root_mean_squared_error: 0.0482 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0367\n",
            "Epoch 18/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0363\n",
            "Epoch 19/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0365\n",
            "Epoch 20/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0365\n",
            "Epoch 21/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0463 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0362\n",
            "Epoch 22/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0463 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0363\n",
            "Epoch 23/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0460 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0364\n",
            "Epoch 24/28\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - root_mean_squared_error: 0.0459 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0362\n",
            "Epoch 25/28\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0457 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0363\n",
            "Epoch 26/28\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0021 - root_mean_squared_error: 0.0456 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0364\n",
            "Epoch 27/28\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0455 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0363\n",
            "Epoch 28/28\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0454 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b9e67ad10>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzfAnjRJ-2zO"
      },
      "source": [
        "### Predicted output outcomes using X_test.\n",
        "y_pred = hypermodel.predict(X_test)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9_IZ1Pdw37u",
        "outputId": "c394075c-3242-482e-b5b3-1fe6fd3af68c"
      },
      "source": [
        "### Evaluate hypermodel using test sets.\n",
        "eval_result = hypermodel.evaluate(X_test, y_test)\n",
        "print(\"[test loss, test rmse]:\", eval_result)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012 - root_mean_squared_error: 0.0350\n",
            "[test loss, test rmse]: [0.001223293598741293, 0.03497561439871788]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-wGJwlK9f5g",
        "outputId": "c3d6649f-b433-4514-a99e-4baf172a63fd"
      },
      "source": [
        "### Find the Root Mean Squared Error\n",
        "RMSE = math.sqrt(np.square(np.subtract(y_test, y_pred)).mean())\n",
        "print('RMSE - MLP: ' + str(RMSE))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE - MLP: 0.034975612261528906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quWd7AeY9Mol"
      },
      "source": [
        "Long Short-Term Memory Model (LSTM - 1 hidden layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sii5ozJwvEs"
      },
      "source": [
        "### Reshape the train, val, test sets,\n",
        "### since LSTMs require 3-dimensional sets.\n",
        "### (samples, time steps, features)\n",
        "#X.shape = (N sequence, length of time series, N input features)\n",
        "#y.shape = (N sequence, length of time series, N targets)\n",
        "#----------> We choose 1 time step for the sequence.\n",
        "X_train_2 = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_val_2 = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "X_test_2 = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "y_train_2 = y_train.reshape(y_train.shape[0], 1, y_train.shape[1])\n",
        "y_val_2 = y_val.reshape(y_val.shape[0], 1, y_val.shape[1])\n",
        "y_test_2 = y_test.reshape(y_test.shape[0], 1, y_test.shape[1])"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGe4_aHxLh2Z"
      },
      "source": [
        "### Create LSTM model with the use of a function.\n",
        "def build_lstm(hp):\n",
        "  hp_units = hp.Int('units', min_value = 10, max_value = 100, step = 10)\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-1, 1e-2, 1e-3, 1e-4])\n",
        "  hp_activation = hp.Choice('activation', values = ['relu', 'tanh', 'sigmoid'])\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add((keras.layers.LSTM(units = hp_units,\n",
        "                               activation = hp_activation,\n",
        "                               input_shape = (X_train_2.shape[1],\n",
        "                                              X_train_2.shape[2]),\n",
        "                               return_sequences = True)))\n",
        "  model.add(keras.layers.Dense(y_train_2.shape[2]))\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate = hp_learning_rate),\n",
        "                loss = 'mse',\n",
        "                metrics = tf.keras.metrics.RootMeanSquaredError())\n",
        "  return model"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHVgbE1APF20"
      },
      "source": [
        "### Instantiate the tuner and perform hyperparameter tuning.\n",
        "lstm_tuner = kt.Hyperband(build_lstm,\n",
        "                     objective = 'val_loss',\n",
        "                     max_epochs = 10,\n",
        "                     directory = 'keras_tuner_dir',\n",
        "                     project_name = 'keras_lstm',\n",
        "                     overwrite = True)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1A-yZg1PF8K"
      },
      "source": [
        "### Early Stopping definition\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGXMCLIaPUD6",
        "outputId": "11624abc-2daa-4f34-9728-ea419581a3f7"
      },
      "source": [
        "### Hyperparameters search for 5 epochs\n",
        "lstm_tuner.search(X_train_2, y_train_2,\n",
        "             epochs = 5, validation_data = (X_val_2, y_val_2),\n",
        "              callbacks = [stop_early])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 05s]\n",
            "val_loss: 0.001718671526759863\n",
            "\n",
            "Best val_loss So Far: 0.0013283481821417809\n",
            "Total elapsed time: 00h 01m 30s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxEm8X1SP1mS"
      },
      "source": [
        "# Get the optimal hyperparameters\n",
        "lstm_best_hps = lstm_tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DXMRbVaP50z",
        "outputId": "cf8e7f9a-d484-4474-c076-49288c75454c"
      },
      "source": [
        "print(f\"\"\"\n",
        "The hyperparameter search for LSTM is complete.\n",
        "The optimal number of units in the first LSTM-connected\n",
        "layer is {lstm_best_hps.get('units')},\n",
        "the optimal activation is {lstm_best_hps.get('activation')}\n",
        "and the optimal learning rate for the optimizer\n",
        "is {lstm_best_hps.get('learning_rate')}\n",
        "\"\"\")"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The hyperparameter search for LSTM is complete.\n",
            "The optimal number of units in the first LSTM-connected\n",
            "layer is 80,\n",
            "the optimal activation is tanh\n",
            "and the optimal learning rate for the optimizer\n",
            "is 0.01\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AMv-h6kP_GI",
        "outputId": "f24ff045-5781-4875-a46a-24b73dc5af08"
      },
      "source": [
        "### Find the optimal number of epochs to train the model with the hyperparameters\n",
        "### obtained from the search.\n",
        "### Build the model with the optimal hyperparameters and\n",
        "### train it on the data for 100 epochs.\n",
        "model = lstm_tuner.hypermodel.build(lstm_best_hps)\n",
        "\n",
        "history = model.fit(X_train_2, y_train_2,\n",
        "                    epochs=100, validation_data = (X_val_2, y_val_2))\n",
        "\n",
        "val_rmse_per_epoch = history.history['val_root_mean_squared_error']\n",
        "\n",
        "best_epoch = val_rmse_per_epoch.index(min(val_rmse_per_epoch))\n",
        "\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 3s 139ms/step - loss: 0.0062 - root_mean_squared_error: 0.0788 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0413\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0040 - root_mean_squared_error: 0.0635 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0036 - root_mean_squared_error: 0.0599 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0386\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0028 - root_mean_squared_error: 0.0531 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - root_mean_squared_error: 0.0493 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0365\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0023 - root_mean_squared_error: 0.0478 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0387\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - root_mean_squared_error: 0.0460 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - root_mean_squared_error: 0.0429 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0428 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0364\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - root_mean_squared_error: 0.0417 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - root_mean_squared_error: 0.0414 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - root_mean_squared_error: 0.0411 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0017 - root_mean_squared_error: 0.0417 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0419 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0017 - root_mean_squared_error: 0.0409 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - root_mean_squared_error: 0.0409 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - root_mean_squared_error: 0.0403 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - root_mean_squared_error: 0.0408 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0399\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - root_mean_squared_error: 0.0402 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - root_mean_squared_error: 0.0393 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0391\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - root_mean_squared_error: 0.0400 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - root_mean_squared_error: 0.0391 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0381\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - root_mean_squared_error: 0.0389 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - root_mean_squared_error: 0.0397 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0016 - root_mean_squared_error: 0.0400 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0390\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - root_mean_squared_error: 0.0398 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - root_mean_squared_error: 0.0401 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0016 - root_mean_squared_error: 0.0404 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0379\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - root_mean_squared_error: 0.0387 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0399\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - root_mean_squared_error: 0.0384 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - root_mean_squared_error: 0.0382 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0388\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - root_mean_squared_error: 0.0388 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0383\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - root_mean_squared_error: 0.0387 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - root_mean_squared_error: 0.0395 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0016 - root_mean_squared_error: 0.0401 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - root_mean_squared_error: 0.0404 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0379\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - root_mean_squared_error: 0.0395 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0389\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - root_mean_squared_error: 0.0402 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0016 - root_mean_squared_error: 0.0402 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - root_mean_squared_error: 0.0387 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - root_mean_squared_error: 0.0383 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - root_mean_squared_error: 0.0394 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - root_mean_squared_error: 0.0370 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - root_mean_squared_error: 0.0368 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - root_mean_squared_error: 0.0363 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0381\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - root_mean_squared_error: 0.0363 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0388\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - root_mean_squared_error: 0.0362 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0381\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - root_mean_squared_error: 0.0355 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0379\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - root_mean_squared_error: 0.0359 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - root_mean_squared_error: 0.0358 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0353 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - root_mean_squared_error: 0.0354 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - root_mean_squared_error: 0.0352 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - root_mean_squared_error: 0.0346 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0345 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - root_mean_squared_error: 0.0352 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - root_mean_squared_error: 0.0345 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - root_mean_squared_error: 0.0343 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - root_mean_squared_error: 0.0342 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0339 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0346 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0346 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0343 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0341 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0333 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - root_mean_squared_error: 0.0329 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0332 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0342 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - root_mean_squared_error: 0.0343 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0339 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - root_mean_squared_error: 0.0326 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - root_mean_squared_error: 0.0327 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - root_mean_squared_error: 0.0319 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - root_mean_squared_error: 0.0324 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - root_mean_squared_error: 0.0321 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - root_mean_squared_error: 0.0330 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0327 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - root_mean_squared_error: 0.0332 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0324 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - root_mean_squared_error: 0.0329 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - root_mean_squared_error: 0.0325 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - root_mean_squared_error: 0.0325 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.9780e-04 - root_mean_squared_error: 0.0316 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.9519e-04 - root_mean_squared_error: 0.0315 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 9.9555e-04 - root_mean_squared_error: 0.0316 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - root_mean_squared_error: 0.0321 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Best epoch: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36schBOyQO8t",
        "outputId": "15ebce3d-80fb-4d4d-d5bf-b3cbe2971dcf"
      },
      "source": [
        "### Pass the optimal hyperparameters to hypermodel.\n",
        "hypermodel_2 = lstm_tuner.hypermodel.build(lstm_best_hps)\n",
        "\n",
        "### Retrain the model with the optimal number of epochs.\n",
        "\n",
        "hypermodel_2.fit(X_train_2, y_train_2,\n",
        "                 epochs = best_epoch,\n",
        "                 validation_data = (X_val_2, y_val_2),\n",
        "                 shuffle = False)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "5/5 [==============================] - 3s 140ms/step - loss: 0.0050 - root_mean_squared_error: 0.0709 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0392\n",
            "Epoch 2/9\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 3/9\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0405\n",
            "Epoch 4/9\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0028 - root_mean_squared_error: 0.0533 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
            "Epoch 5/9\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - root_mean_squared_error: 0.0491 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
            "Epoch 6/9\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0022 - root_mean_squared_error: 0.0467 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0367\n",
            "Epoch 7/9\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - root_mean_squared_error: 0.0452 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 8/9\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 9/9\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - root_mean_squared_error: 0.0429 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b9ee2da10>"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbliTyfRQeO-"
      },
      "source": [
        "### Predicted values using X_test_2.\n",
        "y_pred_lstm = hypermodel_2.predict(X_test_2)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0FBBPpCQiGL",
        "outputId": "4fbc4896-bc7e-40d1-8d80-10ef297fae44"
      },
      "source": [
        "### Evaluate the hypermodel using the test sets.\n",
        "eval_result_lstm = hypermodel_2.evaluate(X_test_2, y_test_2)\n",
        "print(\"[test loss, test mse]:\", eval_result_lstm)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 5ms/step - loss: 0.0012 - root_mean_squared_error: 0.0353\n",
            "[test loss, test mse]: [0.001247358974069357, 0.03531797230243683]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyu2uuORQ0AC",
        "outputId": "02ee3210-cf1d-4c34-cef5-3064d5f0d64b"
      },
      "source": [
        "### Find the Root Mean Squared Error.\n",
        "RMSE_LSTM = math.sqrt(np.square(np.subtract(y_test_2, y_pred_lstm)).mean())\n",
        "print('RMSE - LSTM: ' + str(RMSE_LSTM))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE - LSTM: 0.035317970425821486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHc8OlMnooG5"
      },
      "source": [
        "Long Short-Term Memory Model (LSTM - 2 hidden layers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyikqpdnUzHU"
      },
      "source": [
        "### Create LSTM model with the use of a function\n",
        "def build_lstm_2(hp):\n",
        "  hp_units = hp.Int('units', min_value = 10, max_value = 100, step = 10)\n",
        "  hp_learning_rate = hp.Choice('learning_rate',\n",
        "                               values = [1e-1, 1e-2, 1e-3, 1e-4])\n",
        "  hp_activation = hp.Choice('activation',\n",
        "                            values = ['relu', 'tanh', 'sigmoid'])\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add((keras.layers.LSTM(units = hp_units,\n",
        "                               activation = hp_activation,\n",
        "                               input_shape = (X_train_2.shape[1],\n",
        "                                              X_train_2.shape[2]),\n",
        "                               return_sequences = True)))\n",
        "  model.add((keras.layers.LSTM(units = hp_units,\n",
        "                               activation = hp_activation,\n",
        "                               return_sequences = True)))\n",
        "  model.add(keras.layers.Dense(y_train_2.shape[2]))\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate = hp_learning_rate),\n",
        "                loss = 'mse',\n",
        "                metrics = tf.keras.metrics.RootMeanSquaredError())\n",
        "  return model"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5gDjDNCUzRV"
      },
      "source": [
        "### Instantiate the tuner and perform hyperparameter tuning.\n",
        "lstm_tuner_2 = kt.Hyperband(build_lstm_2,\n",
        "                     objective = 'val_loss',\n",
        "                     max_epochs = 10,\n",
        "                     directory = 'keras_tuner_dir',\n",
        "                     project_name = 'keras_lstm',\n",
        "                     overwrite = True)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPf98YP-UzVo"
      },
      "source": [
        "### Early Stopping definition.\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZWO7YMjUzYr",
        "outputId": "95f59907-aa0d-4b1b-8c3f-2d84fc95b816"
      },
      "source": [
        "### Hyperparameters search for 5 epochs.\n",
        "lstm_tuner_2.search(X_train_2, y_train_2,\n",
        "             epochs = 5, validation_data = (X_val_2, y_val_2),\n",
        "              callbacks = [stop_early])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 04s]\n",
            "val_loss: 0.0014521593693643808\n",
            "\n",
            "Best val_loss So Far: 0.0013338770950213075\n",
            "Total elapsed time: 00h 02m 36s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WJ04A-uUzb_"
      },
      "source": [
        "# Get the optimal hyperparameters.\n",
        "lstm_best_hps_2 = lstm_tuner_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc3H-HQSUzes",
        "outputId": "f0bf1955-1c65-4e9c-877c-2c943d17b531"
      },
      "source": [
        "print(f\"\"\"\n",
        "The hyperparameter search for LSTM (2 layers) is complete. \n",
        "The optimal number of units is {lstm_best_hps_2.get('units')},\n",
        "the optimal activation is {lstm_best_hps_2.get('activation')}\n",
        "and the optimal learning rate for the optimizer\n",
        "is {lstm_best_hps_2.get('learning_rate')}\n",
        "\"\"\")"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The hyperparameter search for LSTM (2 layers) is complete. \n",
            "The optimal number of units is 100,\n",
            "the optimal activation is tanh\n",
            "and the optimal learning rate for the optimizer\n",
            "is 0.01\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygy4_1PFWHdf",
        "outputId": "d7eed84c-2865-4ee2-a8a7-889868454489"
      },
      "source": [
        "### Find the optimal number of epochs to train the model\n",
        "### with the hyperparameters obtained from the search.\n",
        "### Build the model with the optimal hyperparameters\n",
        "### and train it on the data for 100 epochs.\n",
        "model = lstm_tuner_2.hypermodel.build(lstm_best_hps_2)\n",
        "\n",
        "history = model.fit(X_train_2, y_train_2,\n",
        "                    epochs=100, validation_data = (X_val_2, y_val_2))\n",
        "\n",
        "val_rmse_per_epoch = history.history['val_root_mean_squared_error']\n",
        "\n",
        "best_epoch = val_rmse_per_epoch.index(min(val_rmse_per_epoch))\n",
        "\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 5s 238ms/step - loss: 0.0040 - root_mean_squared_error: 0.0632 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0387\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0031 - root_mean_squared_error: 0.0556 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0028 - root_mean_squared_error: 0.0531 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0390\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0027 - root_mean_squared_error: 0.0515 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0025 - root_mean_squared_error: 0.0502 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0023 - root_mean_squared_error: 0.0483 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - root_mean_squared_error: 0.0460 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - root_mean_squared_error: 0.0433 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - root_mean_squared_error: 0.0427 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0364\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - root_mean_squared_error: 0.0416 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0379\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - root_mean_squared_error: 0.0420 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - root_mean_squared_error: 0.0414 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - root_mean_squared_error: 0.0406 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - root_mean_squared_error: 0.0412 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0387\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0017 - root_mean_squared_error: 0.0415 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0360\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - root_mean_squared_error: 0.0413 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - root_mean_squared_error: 0.0418 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0016 - root_mean_squared_error: 0.0406 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0362\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - root_mean_squared_error: 0.0411 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - root_mean_squared_error: 0.0400 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0390\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - root_mean_squared_error: 0.0398 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0365\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0016 - root_mean_squared_error: 0.0402 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - root_mean_squared_error: 0.0395 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - root_mean_squared_error: 0.0403 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - root_mean_squared_error: 0.0397 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0364\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0015 - root_mean_squared_error: 0.0386 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0392\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - root_mean_squared_error: 0.0397 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - root_mean_squared_error: 0.0416 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - root_mean_squared_error: 0.0381 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - root_mean_squared_error: 0.0386 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - root_mean_squared_error: 0.0377 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - root_mean_squared_error: 0.0381 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - root_mean_squared_error: 0.0373 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0379\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - root_mean_squared_error: 0.0369 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - root_mean_squared_error: 0.0366 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - root_mean_squared_error: 0.0363 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - root_mean_squared_error: 0.0370 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - root_mean_squared_error: 0.0364 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - root_mean_squared_error: 0.0355 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - root_mean_squared_error: 0.0354 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - root_mean_squared_error: 0.0358 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - root_mean_squared_error: 0.0356 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0379\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0012 - root_mean_squared_error: 0.0348 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0012 - root_mean_squared_error: 0.0346 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0012 - root_mean_squared_error: 0.0345 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0012 - root_mean_squared_error: 0.0347 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0012 - root_mean_squared_error: 0.0342 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0337 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0338 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - root_mean_squared_error: 0.0333 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0011 - root_mean_squared_error: 0.0332 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0379\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0333 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0329 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0367\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - root_mean_squared_error: 0.0332 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0011 - root_mean_squared_error: 0.0329 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - root_mean_squared_error: 0.0328 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0383\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0336 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0366\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - root_mean_squared_error: 0.0327 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0365\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0010 - root_mean_squared_error: 0.0318 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0010 - root_mean_squared_error: 0.0322 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.9901e-04 - root_mean_squared_error: 0.0316 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9.7582e-04 - root_mean_squared_error: 0.0312 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.4409e-04 - root_mean_squared_error: 0.0307 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.3574e-04 - root_mean_squared_error: 0.0306 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.0664e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8.9308e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.1895e-04 - root_mean_squared_error: 0.0303 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.3105e-04 - root_mean_squared_error: 0.0305 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.9068e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.0499e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.5466e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0373\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.4065e-04 - root_mean_squared_error: 0.0290 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.4771e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 8.9386e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0379\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.8957e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0379\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8.9605e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.4569e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0384\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8.8024e-04 - root_mean_squared_error: 0.0297 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.3130e-04 - root_mean_squared_error: 0.0305 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.9225e-04 - root_mean_squared_error: 0.0281 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0381\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8.4323e-04 - root_mean_squared_error: 0.0290 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.7649e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.7171e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0391\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.1700e-04 - root_mean_squared_error: 0.0268 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.7030e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0380\n",
            "Best epoch: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OENNp8dHWHgN",
        "outputId": "46d419c4-f883-4d70-d7bc-56cde5f85d0e"
      },
      "source": [
        "### Pass the optimal hyperparameters to hypermodel.\n",
        "hypermodel_2_2 = lstm_tuner_2.hypermodel.build(lstm_best_hps_2)\n",
        "\n",
        "### Retrain the model with the optimal number of epochs.\n",
        "hypermodel_2_2.fit(X_train_2, y_train_2,\n",
        "                 epochs = best_epoch,\n",
        "                 validation_data = (X_val_2, y_val_2),\n",
        "                 shuffle = False)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "5/5 [==============================] - 5s 238ms/step - loss: 0.0038 - root_mean_squared_error: 0.0616 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0383\n",
            "Epoch 2/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0031 - root_mean_squared_error: 0.0553 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0376\n",
            "Epoch 3/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0028 - root_mean_squared_error: 0.0527 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0378\n",
            "Epoch 4/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0026 - root_mean_squared_error: 0.0515 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 5/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0024 - root_mean_squared_error: 0.0486 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 6/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0367\n",
            "Epoch 7/16\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0020 - root_mean_squared_error: 0.0445 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0371\n",
            "Epoch 8/16\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0019 - root_mean_squared_error: 0.0432 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0372\n",
            "Epoch 9/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - root_mean_squared_error: 0.0424 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 10/16\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - root_mean_squared_error: 0.0424 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 11/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - root_mean_squared_error: 0.0426 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 12/16\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - root_mean_squared_error: 0.0419 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0383\n",
            "Epoch 13/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - root_mean_squared_error: 0.0415 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0370\n",
            "Epoch 14/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0386\n",
            "Epoch 15/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0016 - root_mean_squared_error: 0.0405 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 16/16\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0016 - root_mean_squared_error: 0.0403 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0381\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b9ccc4350>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avtDZhSDWHi9"
      },
      "source": [
        "### Predicted output values using X_test_2.\n",
        "y_pred_lstm_2 = hypermodel_2_2.predict(X_test_2)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryz50DOVWxtH",
        "outputId": "770ce10a-3d75-40f9-a095-a269dc786870"
      },
      "source": [
        "### Evalaute hypermodel using test sets.\n",
        "eval_result_lstm = hypermodel_2_2.evaluate(X_test_2, y_test_2)\n",
        "print(\"[test loss, test mse]:\", eval_result_lstm)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 8ms/step - loss: 0.0013 - root_mean_squared_error: 0.0364\n",
            "[test loss, test mse]: [0.0013238996034488082, 0.0363854318857193]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSz4cg1mWxvz",
        "outputId": "96154922-fa49-49b0-f63b-dce0d012a533"
      },
      "source": [
        "### Find the Root Mean Squared Error\n",
        "RMSE_LSTM_2 = math.sqrt(np.square(np.subtract(y_test_2, y_pred_lstm_2)).mean())\n",
        "print('RMSE - LSTM 2: ' + str(RMSE_LSTM_2))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE - LSTM 2: 0.036385431898619106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_3OlDz_qiD0"
      },
      "source": [
        "Mean Variance Portfolio Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91e4_N9j3wqK"
      },
      "source": [
        "Historical Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHxU28CU3sV8"
      },
      "source": [
        "### Financial variables\n",
        "NAESX = pd.read_csv('NAESX.csv', sep = ',', index_col = 0)\n",
        "NAESX.index = pd.to_datetime(NAESX.index)\n",
        "NAESX = NAESX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "NAESX.columns = ['NAESX']\n",
        "\n",
        "VBMFX = pd.read_csv('VBMFX.csv', sep = ',', index_col = 0)\n",
        "VBMFX.index = pd.to_datetime(VBMFX.index)\n",
        "VBMFX = VBMFX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VBMFX.columns = ['VBMFX']\n",
        "\n",
        "VEIEX = pd.read_csv('VEIEX.csv', sep = ',', index_col = 0)\n",
        "VEIEX.index = pd.to_datetime(VEIEX.index)\n",
        "VEIEX = VEIEX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VEIEX.columns = ['VEIEX']\n",
        "\n",
        "VFINX = pd.read_csv('VFINX.csv', sep = ',', index_col = 0)\n",
        "VFINX.index = pd.to_datetime(VFINX.index)\n",
        "VFINX = VFINX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VFINX.columns = ['VFINX']\n",
        "\n",
        "VGSLX = pd.read_csv('VGSLX.csv', sep = ',', index_col = 0)\n",
        "VGSLX.index = pd.to_datetime(VGSLX.index)\n",
        "VGSLX = VGSLX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VGSLX.columns = ['VGSLX']\n",
        "\n",
        "VGTSX = pd.read_csv('VGTSX.csv', sep = ',', index_col = 0)\n",
        "VGTSX.index = pd.to_datetime(VGTSX.index)\n",
        "VGTSX = VGTSX.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "VGTSX.columns = ['VGTSX']\n",
        "\n",
        "mutual_funds = [NAESX, VBMFX, VEIEX, VFINX, VGSLX, VGTSX]\n",
        "mutual_funds_prices = reduce(lambda left, right : pd.merge(left, right,\n",
        "                                         left_index = True, right_index = True,\n",
        "                                         how = 'outer'), mutual_funds)\n",
        "mutual_funds_prices = mutual_funds_prices['2002-01-01' : '2019-12-01']\n",
        "mutual_funds_prices = mutual_funds_prices.fillna(0.0)\n",
        "mutual_funds_returns = mutual_funds_prices.pct_change().apply(lambda x: np.log(1+x))"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xopfQkYM3sYz",
        "outputId": "ed53a382-ba27-4281-b053-2e46f106739e"
      },
      "source": [
        "### Find mean monthly return and covariance of monthly returns.\n",
        "mean_monthly_returns = mutual_funds_returns.mean()\n",
        "cov_matrix = mutual_funds_returns.cov()\n",
        " \n",
        "### Assuming portfolio weights are equally set.\n",
        "weights = np.asarray([1/6, 1/6, 1/6, 1/6, 1/6, 1/6])\n",
        " \n",
        "portfolio_return = round(np.sum(mean_monthly_returns * weights) * 12,2)\n",
        "portfolio_std_dev = round(np.sqrt(np.dot(weights.T,np.dot(cov_matrix, weights))) * np.sqrt(12),2)\n",
        "\n",
        "print(\"Expected annualised return: \" + str(portfolio_return))\n",
        "print(\"Volatility: \" + str(portfolio_std_dev))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected annualised return: 0.08\n",
            "Volatility: 0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-AIdNr33sbi",
        "outputId": "51a77492-388c-42c2-f062-8618c53f4bc3"
      },
      "source": [
        "### Portfolio optimization, minimizing volatility.\n",
        "### The output is an array of weights for each stock.\n",
        "\n",
        "### Expected returns and sample covariance.\n",
        "mu = expected_returns.mean_historical_return(mutual_funds_prices)\n",
        "S = risk_models.sample_cov(mutual_funds_prices)\n",
        "\n",
        "# Optimise portfolio, minimizing volatility.\n",
        "ef = EfficientFrontier(mu, S)\n",
        "raw_weights = ef.min_volatility()\n",
        "cleaned_weights = ef.clean_weights()\n",
        "print(cleaned_weights)\n",
        "ef.portfolio_performance(verbose=True)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('NAESX', 0.00776), ('VBMFX', 0.9267), ('VEIEX', 0.0), ('VFINX', 0.06554), ('VGSLX', 0.0), ('VGTSX', 0.0)])\n",
            "Expected annual return: 154.5%\n",
            "Annual volatility: 15.1%\n",
            "Sharpe Ratio: 10.10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.545380301070697, 0.15101006155691746, 10.101183228084198)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PODrpGMZ4KJk",
        "outputId": "2bb89baa-de87-426b-9dc8-47fb2140e4db"
      },
      "source": [
        "### Weights' allocation to discrete values, showing the number of shares\n",
        "### of each mutual fund index an investor should buy in order to minimize\n",
        "### volatility.\n",
        "from pypfopt import  discrete_allocation\n",
        "from pypfopt.discrete_allocation import  DiscreteAllocation\n",
        "latest_prices = discrete_allocation.get_latest_prices(mutual_funds_prices)\n",
        "allocation, leftover = discrete_allocation.DiscreteAllocation(cleaned_weights, latest_prices, total_portfolio_value=100000).lp_portfolio()\n",
        "print(allocation)\n",
        "print(\"Funds remaining: ${:.2f}\".format(leftover))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NAESX': 9, 'VBMFX': 8662, 'VFINX': 23}\n",
            "Funds remaining: $0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyXcqvlmv1jU"
      },
      "source": [
        "Predicted Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7IJ6NeVcmUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f53cd3c-f36f-42cd-998b-978101549bc3"
      },
      "source": [
        "### Find the predicted values of LSTM model (1 hidden layer)\n",
        "### and concatenate it into one array.\n",
        "y_pred_lstm_tr = hypermodel_2.predict(X_train_2)\n",
        "y_pred_lstm_val = hypermodel_2.predict(X_val_2)\n",
        "y_pred_lstm_test = hypermodel_2.predict(X_test_2)\n",
        "lstm_predicted_returns = np.concatenate((y_pred_lstm_tr,\n",
        "                                         y_pred_lstm_val,\n",
        "                                         y_pred_lstm_test), axis = 0)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.02383673, -0.0052248 ,  0.01711401, -0.00722454,\n",
              "         -0.00013061, -0.00104558]],\n",
              "\n",
              "       [[ 0.01208617, -0.00188858,  0.00762723,  0.00899113,\n",
              "          0.00364275,  0.00299242]],\n",
              "\n",
              "       [[ 0.02814865, -0.00867448,  0.04551662,  0.02492215,\n",
              "          0.01403879,  0.02414655]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.01373366,  0.00157472,  0.01031494,  0.01060112,\n",
              "          0.01836428,  0.01028183]],\n",
              "\n",
              "       [[ 0.01385377,  0.00131663,  0.012086  ,  0.01071692,\n",
              "          0.01693846,  0.01046304]],\n",
              "\n",
              "       [[ 0.0139853 ,  0.00088097,  0.01245499,  0.0109985 ,\n",
              "          0.0164239 ,  0.01021497]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPnZquJPe1VS",
        "outputId": "2cbf4f02-f865-4a6f-932b-18295240d1c2"
      },
      "source": [
        "### Reshape the predicted array.\n",
        "lstm_predicted_returns = lstm_predicted_returns.reshape((216,6))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02383673, -0.0052248 ,  0.01711401, -0.00722454, -0.00013061,\n",
              "        -0.00104558],\n",
              "       [ 0.01208617, -0.00188858,  0.00762723,  0.00899113,  0.00364275,\n",
              "         0.00299242],\n",
              "       [ 0.02814865, -0.00867448,  0.04551662,  0.02492215,  0.01403879,\n",
              "         0.02414655],\n",
              "       ...,\n",
              "       [ 0.01373366,  0.00157472,  0.01031494,  0.01060112,  0.01836428,\n",
              "         0.01028183],\n",
              "       [ 0.01385377,  0.00131663,  0.012086  ,  0.01071692,  0.01693846,\n",
              "         0.01046304],\n",
              "       [ 0.0139853 ,  0.00088097,  0.01245499,  0.0109985 ,  0.0164239 ,\n",
              "         0.01021497]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvTrvoweivoc",
        "outputId": "086a5457-27d8-4c53-8b9b-c39784dd0ed2"
      },
      "source": [
        "### Remove standardization effects.\n",
        "### NOTE: The mean and standard deviation are so small,\n",
        "### that no changes are observed after removal. \n",
        "lstm_predicted_returns = lstm_predicted_returns * X_train.std() + X_train.mean()"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02383673, -0.0052248 ,  0.01711401, -0.00722454, -0.00013061,\n",
              "        -0.00104558],\n",
              "       [ 0.01208617, -0.00188858,  0.00762723,  0.00899113,  0.00364275,\n",
              "         0.00299242],\n",
              "       [ 0.02814865, -0.00867448,  0.04551662,  0.02492215,  0.01403879,\n",
              "         0.02414655],\n",
              "       ...,\n",
              "       [ 0.01373366,  0.00157472,  0.01031494,  0.01060112,  0.01836428,\n",
              "         0.01028183],\n",
              "       [ 0.01385377,  0.00131663,  0.012086  ,  0.01071692,  0.01693846,\n",
              "         0.01046304],\n",
              "       [ 0.0139853 ,  0.00088097,  0.01245499,  0.0109985 ,  0.0164239 ,\n",
              "         0.01021497]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mfdYsZ-yOBx",
        "outputId": "3e4b9fdf-7f66-4e34-9458-eace17f320c3"
      },
      "source": [
        "### Convert array to dataframe.\n",
        "lstm_predicted_returns_df = pd.DataFrame(lstm_predicted_returns,\n",
        "                                         columns = ['NAESX', 'VBMFX',\n",
        "                                                    'VEIEX', 'VFINX',\n",
        "                                                    'VGSLX', 'VGTSX'])"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        NAESX     VBMFX     VEIEX     VFINX     VGSLX     VGTSX\n",
            "0    0.023837 -0.005225  0.017114 -0.007225 -0.000131 -0.001046\n",
            "1    0.012086 -0.001889  0.007627  0.008991  0.003643  0.002992\n",
            "2    0.028149 -0.008674  0.045517  0.024922  0.014039  0.024147\n",
            "3    0.010194  0.003750  0.017355  0.007872  0.014285  0.015250\n",
            "4    0.032493  0.000048  0.049856  0.021130  0.031813  0.038386\n",
            "..        ...       ...       ...       ...       ...       ...\n",
            "211  0.012089  0.000757  0.005544  0.008934  0.014135  0.005248\n",
            "212  0.013805  0.000928  0.011013  0.010751  0.016135  0.009311\n",
            "213  0.013734  0.001575  0.010315  0.010601  0.018364  0.010282\n",
            "214  0.013854  0.001317  0.012086  0.010717  0.016938  0.010463\n",
            "215  0.013985  0.000881  0.012455  0.010998  0.016424  0.010215\n",
            "\n",
            "[216 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQP1dyOf4pWc",
        "outputId": "a5b45fb7-ffa0-4a6f-9c47-4ed74e839efe"
      },
      "source": [
        "### Find mean monthly return and covariance of monthly returns.\n",
        "mean_monthly_returns = lstm_predicted_returns_df.mean()\n",
        "cov_matrix = lstm_predicted_returns_df.cov()\n",
        " \n",
        "### Assuming portfolio weights are equally set.\n",
        "weights = np.asarray([1/6, 1/6, 1/6, 1/6, 1/6, 1/6])\n",
        " \n",
        "portfolio_return = round(np.sum(mean_monthly_returns * weights) * 12,2)\n",
        "portfolio_std_dev = round(np.sqrt(np.dot(weights.T,np.dot(cov_matrix, weights))) * np.sqrt(12),2)\n",
        "\n",
        "print(\"Expected annualised return: \" + str(portfolio_return))\n",
        "print(\"Volatility: \" + str(portfolio_std_dev))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected annualised return: 0.09\n",
            "Volatility: 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KDsbcd803LP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "f9ca2523-1519-4f99-bc6b-d04207fe63e5"
      },
      "source": [
        "### Transform from logarithmic returns to values.\n",
        "### Use actual initial values as initial values in the process of transformation.\n",
        "lstm_predicted_returns_df = (lstm_predicted_returns_df + 1).cumprod()\n",
        "lstm_predicted_returns_df['NAESX'] = mutual_funds_prices['NAESX'][0] * lstm_predicted_returns_df['NAESX']\n",
        "lstm_predicted_returns_df['VBMFX'] = mutual_funds_prices['VBMFX'][0] * lstm_predicted_returns_df['VBMFX']\n",
        "lstm_predicted_returns_df['VEIEX'] = mutual_funds_prices['VEIEX'][0] * lstm_predicted_returns_df['VEIEX']\n",
        "lstm_predicted_returns_df['VFINX'] = mutual_funds_prices['VFINX'][0] * lstm_predicted_returns_df['VFINX']\n",
        "lstm_predicted_returns_df['VGSLX'] = mutual_funds_prices['VGSLX'][0] * lstm_predicted_returns_df['VGSLX']\n",
        "lstm_predicted_returns_df['VGTSX'] = mutual_funds_prices['VGTSX'][0] * lstm_predicted_returns_df['VGTSX']"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NAESX</th>\n",
              "      <th>VBMFX</th>\n",
              "      <th>VEIEX</th>\n",
              "      <th>VFINX</th>\n",
              "      <th>VGSLX</th>\n",
              "      <th>VGTSX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.725772</td>\n",
              "      <td>5.166609</td>\n",
              "      <td>5.564115</td>\n",
              "      <td>71.949310</td>\n",
              "      <td>25.507135</td>\n",
              "      <td>5.310537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.915836</td>\n",
              "      <td>5.156851</td>\n",
              "      <td>5.606554</td>\n",
              "      <td>72.596214</td>\n",
              "      <td>25.600056</td>\n",
              "      <td>5.326429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.363844</td>\n",
              "      <td>5.112118</td>\n",
              "      <td>5.861745</td>\n",
              "      <td>74.405464</td>\n",
              "      <td>25.959450</td>\n",
              "      <td>5.455044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.530659</td>\n",
              "      <td>5.131287</td>\n",
              "      <td>5.963476</td>\n",
              "      <td>74.991150</td>\n",
              "      <td>26.330286</td>\n",
              "      <td>5.538235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.067799</td>\n",
              "      <td>5.131534</td>\n",
              "      <td>6.260792</td>\n",
              "      <td>76.575737</td>\n",
              "      <td>27.167933</td>\n",
              "      <td>5.750826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>121.480919</td>\n",
              "      <td>8.872168</td>\n",
              "      <td>27.710264</td>\n",
              "      <td>303.784546</td>\n",
              "      <td>162.364639</td>\n",
              "      <td>22.876333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>123.158028</td>\n",
              "      <td>8.880399</td>\n",
              "      <td>28.015442</td>\n",
              "      <td>307.050690</td>\n",
              "      <td>164.984375</td>\n",
              "      <td>23.089346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>124.849434</td>\n",
              "      <td>8.894383</td>\n",
              "      <td>28.304420</td>\n",
              "      <td>310.305786</td>\n",
              "      <td>168.014206</td>\n",
              "      <td>23.326744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>126.579063</td>\n",
              "      <td>8.906095</td>\n",
              "      <td>28.646509</td>\n",
              "      <td>313.631317</td>\n",
              "      <td>170.860092</td>\n",
              "      <td>23.570814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>128.349304</td>\n",
              "      <td>8.913940</td>\n",
              "      <td>29.003302</td>\n",
              "      <td>317.080750</td>\n",
              "      <td>173.666290</td>\n",
              "      <td>23.811586</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          NAESX     VBMFX      VEIEX       VFINX       VGSLX      VGTSX\n",
              "0     15.725772  5.166609   5.564115   71.949310   25.507135   5.310537\n",
              "1     15.915836  5.156851   5.606554   72.596214   25.600056   5.326429\n",
              "2     16.363844  5.112118   5.861745   74.405464   25.959450   5.455044\n",
              "3     16.530659  5.131287   5.963476   74.991150   26.330286   5.538235\n",
              "4     17.067799  5.131534   6.260792   76.575737   27.167933   5.750826\n",
              "..          ...       ...        ...         ...         ...        ...\n",
              "211  121.480919  8.872168  27.710264  303.784546  162.364639  22.876333\n",
              "212  123.158028  8.880399  28.015442  307.050690  164.984375  23.089346\n",
              "213  124.849434  8.894383  28.304420  310.305786  168.014206  23.326744\n",
              "214  126.579063  8.906095  28.646509  313.631317  170.860092  23.570814\n",
              "215  128.349304  8.913940  29.003302  317.080750  173.666290  23.811586\n",
              "\n",
              "[216 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBOW8WIfv0L9",
        "outputId": "c2aa05df-f37f-480e-c1aa-713a9f02e25b"
      },
      "source": [
        "### Portfolio optimization, minimizing volatility.\n",
        "### The output is an array of weights for each stock.\n",
        "\n",
        "### Expected returns and sample covariance.\n",
        "mu = expected_returns.mean_historical_return(lstm_predicted_returns_df)\n",
        "S = risk_models.sample_cov(lstm_predicted_returns_df)\n",
        "\n",
        "### Optimise portfolio, minimizing volatility.\n",
        "ef = EfficientFrontier(mu, S)\n",
        "raw_weights = ef.min_volatility()\n",
        "cleaned_weights = ef.clean_weights()\n",
        "print(cleaned_weights)\n",
        "ef.portfolio_performance(verbose=True)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('NAESX', 0.20128), ('VBMFX', 0.77627), ('VEIEX', 0.0), ('VFINX', 0.02245), ('VGSLX', 0.0), ('VGTSX', 0.0)])\n",
            "Expected annual return: 295.7%\n",
            "Annual volatility: 12.5%\n",
            "Sharpe Ratio: 23.49\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.956547866266688, 0.1250344458745462, 23.485910988185488)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiKWYSXkwAsi",
        "outputId": "cb7799d1-f3b7-48c0-acad-b7fdec45289b"
      },
      "source": [
        "### Weights' allocation to discrete values, showing the number of shares\n",
        "### of each mutual fund index an investor should buy in order to minimize\n",
        "### volatility.\n",
        "\n",
        "latest_prices = discrete_allocation.get_latest_prices(lstm_predicted_returns_df)\n",
        "allocation, leftover = discrete_allocation.DiscreteAllocation(cleaned_weights, latest_prices, total_portfolio_value=100000).lp_portfolio()\n",
        "print(allocation)\n",
        "print(\"Funds remaining: ${:.2f}\".format(leftover))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NAESX': 157, 'VBMFX': 8708, 'VFINX': 7}\n",
            "Funds remaining: $7.00\n"
          ]
        }
      ]
    }
  ]
}